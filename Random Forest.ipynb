{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QzHGkdwr7gy"
      },
      "source": [
        "# 1. Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:43:59.191061Z",
          "iopub.status.busy": "2022-03-25T02:43:59.190782Z",
          "iopub.status.idle": "2022-03-25T02:44:40.939582Z",
          "shell.execute_reply": "2022-03-25T02:44:40.938473Z",
          "shell.execute_reply.started": "2022-03-25T02:43:59.191032Z"
        },
        "id": "ZMjPBGi8WQc_",
        "outputId": "b75a4cd4-6080-4d9c-be73-8bcc08b9f2d7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-md==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.2.0/en_core_web_md-3.2.0-py3-none-any.whl (45.7 MB)\n",
            "     |████████████████████████████████| 45.7 MB 56.7 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-md==3.2.0) (3.2.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.26.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.20.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.7.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.8.2)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (21.3)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (59.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.11.2)\n",
            "Installing collected packages: typing-extensions, en-core-web-md\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\n",
            "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\n",
            "tensorflow 2.6.2 requires numpy~=1.19.2, but you have numpy 1.20.3 which is incompatible.\n",
            "tensorflow 2.6.2 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "tensorflow 2.6.2 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "tensorflow 2.6.2 requires wrapt~=1.12.1, but you have wrapt 1.13.3 which is incompatible.\n",
            "tensorflow-transform 1.5.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\n",
            "tensorflow-transform 1.5.0 requires numpy<1.20,>=1.16, but you have numpy 1.20.3 which is incompatible.\n",
            "tensorflow-transform 1.5.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.1 which is incompatible.\n",
            "tensorflow-transform 1.5.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.2, but you have tensorflow 2.6.2 which is incompatible.\n",
            "tensorflow-serving-api 2.7.0 requires tensorflow<3,>=2.7.0, but you have tensorflow 2.6.2 which is incompatible.\n",
            "flake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.2 which is incompatible.\n",
            "apache-beam 2.34.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\n",
            "apache-beam 2.34.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.2 which is incompatible.\n",
            "apache-beam 2.34.0 requires pyarrow<6.0.0,>=0.15.1, but you have pyarrow 6.0.1 which is incompatible.\n",
            "aioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "aiobotocore 2.1.1 requires botocore<1.23.25,>=1.23.24, but you have botocore 1.24.8 which is incompatible.\u001b[0m\n",
            "Successfully installed en-core-web-md-3.2.0 typing-extensions-3.10.0.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import numpy as np\n",
        "from multiprocessing import  Pool\n",
        "import spacy\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:44:40.943010Z",
          "iopub.status.busy": "2022-03-25T02:44:40.942653Z",
          "iopub.status.idle": "2022-03-25T02:44:42.378086Z",
          "shell.execute_reply": "2022-03-25T02:44:42.377284Z",
          "shell.execute_reply.started": "2022-03-25T02:44:40.942955Z"
        },
        "id": "EPSmbFtT2egC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/kaggle/input/d/yipeng07/fakenews/fulltrain.csv\",header=None)\n",
        "test = pd.read_csv(\"/kaggle/input/d/yipeng07/fakenews/balancedtest.csv\",header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbQ7wMzuZI-9"
      },
      "source": [
        "# 2. Obtain the basic features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:44:42.379881Z",
          "iopub.status.busy": "2022-03-25T02:44:42.379244Z",
          "iopub.status.idle": "2022-03-25T02:44:42.390134Z",
          "shell.execute_reply": "2022-03-25T02:44:42.389220Z",
          "shell.execute_reply.started": "2022-03-25T02:44:42.379848Z"
        },
        "id": "g82aD1D0WPe1",
        "outputId": "a8257911-1253-424d-ab61-f0b32e296feb",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A little less than a decade ago, hockey fans w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The writers of the HBO series The Sopranos too...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Despite claims from the TV news outlet to offe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>After receiving 'subpar' service and experienc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>At a cafeteria-table press conference Monday, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>Stunned shock and dismay were just a few of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>Speaking with reporters before a game Monday, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>Sports journalists and television crews were p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>SALEM, VAF;or the eighth straight world-histor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                                                  1\n",
              "0  1  A little less than a decade ago, hockey fans w...\n",
              "1  1  The writers of the HBO series The Sopranos too...\n",
              "2  1  Despite claims from the TV news outlet to offe...\n",
              "3  1  After receiving 'subpar' service and experienc...\n",
              "4  1  After watching his beloved Seattle Mariners pr...\n",
              "5  1  At a cafeteria-table press conference Monday, ...\n",
              "6  1  Stunned shock and dismay were just a few of th...\n",
              "7  1  Speaking with reporters before a game Monday, ...\n",
              "8  1  Sports journalists and television crews were p...\n",
              "9  1  SALEM, VAF;or the eighth straight world-histor..."
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the first 10 lines\n",
        "train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:44:42.392379Z",
          "iopub.status.busy": "2022-03-25T02:44:42.392130Z",
          "iopub.status.idle": "2022-03-25T02:44:42.402828Z",
          "shell.execute_reply": "2022-03-25T02:44:42.401959Z",
          "shell.execute_reply.started": "2022-03-25T02:44:42.392347Z"
        },
        "id": "F9tljdjzRMWb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Change columns name\n",
        "train.columns = ['Verdict','Text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:44:42.404211Z",
          "iopub.status.busy": "2022-03-25T02:44:42.403950Z",
          "iopub.status.idle": "2022-03-25T02:44:42.420544Z",
          "shell.execute_reply": "2022-03-25T02:44:42.419689Z",
          "shell.execute_reply.started": "2022-03-25T02:44:42.404166Z"
        },
        "id": "6UZJj_6PSE0i",
        "outputId": "680696e5-47c9-4cf0-bbc3-4d5aa34dccc1",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>When so many actors seem content to churn out ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>In what football insiders are calling an unex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>In a freak accident following Game 3 of the N....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>North Koreas official news agency announced to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>The former Alaska Governor Sarah Palin would b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>With the first Presidential debate just two da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>There are fans, and then there are super-fans....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>With its landmark decisions this week, the Uni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>Koch Industries is defending its acquisition o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>Republican lawmakers asked increasingly tough ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                                                  1\n",
              "0  1  When so many actors seem content to churn out ...\n",
              "1  1   In what football insiders are calling an unex...\n",
              "2  1  In a freak accident following Game 3 of the N....\n",
              "3  1  North Koreas official news agency announced to...\n",
              "4  1  The former Alaska Governor Sarah Palin would b...\n",
              "5  1  With the first Presidential debate just two da...\n",
              "6  1  There are fans, and then there are super-fans....\n",
              "7  1  With its landmark decisions this week, the Uni...\n",
              "8  1  Koch Industries is defending its acquisition o...\n",
              "9  1  Republican lawmakers asked increasingly tough ..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the first 10 lines\n",
        "test.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:44:42.422084Z",
          "iopub.status.busy": "2022-03-25T02:44:42.421850Z",
          "iopub.status.idle": "2022-03-25T02:44:42.432771Z",
          "shell.execute_reply": "2022-03-25T02:44:42.431836Z",
          "shell.execute_reply.started": "2022-03-25T02:44:42.422057Z"
        },
        "id": "q4mK882eSN3N",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Change columns name\n",
        "test.columns = ['Verdict','Text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:44:42.434528Z",
          "iopub.status.busy": "2022-03-25T02:44:42.434212Z",
          "iopub.status.idle": "2022-03-25T02:44:43.907224Z",
          "shell.execute_reply": "2022-03-25T02:44:43.906305Z",
          "shell.execute_reply.started": "2022-03-25T02:44:42.434495Z"
        },
        "id": "jxBVZJ4AWsXq",
        "outputId": "d9ae79cd-1597-465f-a9a1-b234d22ca55f",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A little less than a decade ago, hockey fans w...</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The writers of the HBO series The Sopranos too...</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Despite claims from the TV news outlet to offe...</td>\n",
              "      <td>706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After receiving 'subpar' service and experienc...</td>\n",
              "      <td>706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  word_count\n",
              "0  A little less than a decade ago, hockey fans w...         147\n",
              "1  The writers of the HBO series The Sopranos too...         123\n",
              "2  Despite claims from the TV news outlet to offe...         706\n",
              "3  After receiving 'subpar' service and experienc...         706\n",
              "4  After watching his beloved Seattle Mariners pr...         174"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Word count\n",
        "train['word_count'] = train['Text'].apply(lambda x: len(str(x).split(\" \")))\n",
        "train[['Text', 'word_count']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:44:43.909375Z",
          "iopub.status.busy": "2022-03-25T02:44:43.908689Z",
          "iopub.status.idle": "2022-03-25T02:44:43.977714Z",
          "shell.execute_reply": "2022-03-25T02:44:43.976854Z",
          "shell.execute_reply.started": "2022-03-25T02:44:43.909333Z"
        },
        "id": "T6_v5bjHXD6j",
        "outputId": "51c3f456-dc83-4717-db60-1916e95a744d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>char_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A little less than a decade ago, hockey fans w...</td>\n",
              "      <td>873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The writers of the HBO series The Sopranos too...</td>\n",
              "      <td>715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Despite claims from the TV news outlet to offe...</td>\n",
              "      <td>4443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After receiving 'subpar' service and experienc...</td>\n",
              "      <td>3913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
              "      <td>1058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  char_count\n",
              "0  A little less than a decade ago, hockey fans w...         873\n",
              "1  The writers of the HBO series The Sopranos too...         715\n",
              "2  Despite claims from the TV news outlet to offe...        4443\n",
              "3  After receiving 'subpar' service and experienc...        3913\n",
              "4  After watching his beloved Seattle Mariners pr...        1058"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Char count\n",
        "train['char_count'] = train['Text'].str.len()\n",
        "train[['Text','char_count']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:44:43.979744Z",
          "iopub.status.busy": "2022-03-25T02:44:43.979163Z",
          "iopub.status.idle": "2022-03-25T02:44:47.459465Z",
          "shell.execute_reply": "2022-03-25T02:44:47.458597Z",
          "shell.execute_reply.started": "2022-03-25T02:44:43.979706Z"
        },
        "id": "835HTQdTXR9U",
        "outputId": "11d68766-d655-4c5a-c26e-73af07398857",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>avg_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A little less than a decade ago, hockey fans w...</td>\n",
              "      <td>4.979452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The writers of the HBO series The Sopranos too...</td>\n",
              "      <td>4.860656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Despite claims from the TV news outlet to offe...</td>\n",
              "      <td>5.302128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After receiving 'subpar' service and experienc...</td>\n",
              "      <td>4.550355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
              "      <td>5.115607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  avg_word\n",
              "0  A little less than a decade ago, hockey fans w...  4.979452\n",
              "1  The writers of the HBO series The Sopranos too...  4.860656\n",
              "2  Despite claims from the TV news outlet to offe...  5.302128\n",
              "3  After receiving 'subpar' service and experienc...  4.550355\n",
              "4  After watching his beloved Seattle Mariners pr...  5.115607"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Average word length\n",
        "\n",
        "def avg_word(sentence):\n",
        "    words=sentence.split()\n",
        "    return (sum(len(word) for word in words)/len(words))\n",
        "\n",
        "train['avg_word'] = train['Text'].apply(lambda x:avg_word(x))\n",
        "train[['Text','avg_word']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:44:47.461923Z",
          "iopub.status.busy": "2022-03-25T02:44:47.461613Z",
          "iopub.status.idle": "2022-03-25T02:45:34.383019Z",
          "shell.execute_reply": "2022-03-25T02:45:34.382146Z",
          "shell.execute_reply.started": "2022-03-25T02:44:47.461889Z"
        },
        "id": "IRyGTsYzYT1l",
        "outputId": "5d632949-e1d0-4d26-a0f7-9beaee43c872",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A little less than a decade ago, hockey fans w...</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The writers of the HBO series The Sopranos too...</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Despite claims from the TV news outlet to offe...</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After receiving 'subpar' service and experienc...</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  stopwords\n",
              "0  A little less than a decade ago, hockey fans w...         46\n",
              "1  The writers of the HBO series The Sopranos too...         43\n",
              "2  Despite claims from the TV news outlet to offe...        219\n",
              "3  After receiving 'subpar' service and experienc...        299\n",
              "4  After watching his beloved Seattle Mariners pr...         59"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The number of stop words\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')\n",
        "train['stopwords']=train['Text'].apply(lambda sen:len([x for x in sen.split() if x in stop]))\n",
        "train[['Text','stopwords']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:45:34.384568Z",
          "iopub.status.busy": "2022-03-25T02:45:34.384254Z",
          "iopub.status.idle": "2022-03-25T02:45:38.974531Z",
          "shell.execute_reply": "2022-03-25T02:45:38.973594Z",
          "shell.execute_reply.started": "2022-03-25T02:45:34.384537Z"
        },
        "id": "p6SIcXEZYwOu",
        "outputId": "12d43309-ae9d-4087-bc87-1d8e8f7c6b13",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A little less than a decade ago, hockey fans w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The writers of the HBO series The Sopranos too...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Despite claims from the TV news outlet to offe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After receiving 'subpar' service and experienc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  hashtags\n",
              "0  A little less than a decade ago, hockey fans w...         0\n",
              "1  The writers of the HBO series The Sopranos too...         0\n",
              "2  Despite claims from the TV news outlet to offe...         0\n",
              "3  After receiving 'subpar' service and experienc...         0\n",
              "4  After watching his beloved Seattle Mariners pr...         0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#The number of special chars\n",
        "train['hashtags']=train['Text'].apply(lambda sen:len([x for x in sen.split() if x.startswith(\"#\")]))\n",
        "train[['Text','hashtags']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:45:38.976295Z",
          "iopub.status.busy": "2022-03-25T02:45:38.975842Z",
          "iopub.status.idle": "2022-03-25T02:45:42.063063Z",
          "shell.execute_reply": "2022-03-25T02:45:42.062016Z",
          "shell.execute_reply.started": "2022-03-25T02:45:38.976261Z"
        },
        "id": "SN47R858Y7RJ",
        "outputId": "8b8d8ef5-650f-46dd-9854-50049f41b091",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>numerics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A little less than a decade ago, hockey fans w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The writers of the HBO series The Sopranos too...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Despite claims from the TV news outlet to offe...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After receiving 'subpar' service and experienc...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  numerics\n",
              "0  A little less than a decade ago, hockey fans w...         0\n",
              "1  The writers of the HBO series The Sopranos too...         1\n",
              "2  Despite claims from the TV news outlet to offe...        20\n",
              "3  After receiving 'subpar' service and experienc...         5\n",
              "4  After watching his beloved Seattle Mariners pr...         0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#The number of numerics\n",
        "train['numerics']=train['Text'].apply(lambda sen:len([x for x in sen.split() if x.isdigit()]))\n",
        "train[['Text','numerics']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:45:42.064723Z",
          "iopub.status.busy": "2022-03-25T02:45:42.064504Z",
          "iopub.status.idle": "2022-03-25T02:45:45.182126Z",
          "shell.execute_reply": "2022-03-25T02:45:45.181306Z",
          "shell.execute_reply.started": "2022-03-25T02:45:42.064696Z"
        },
        "id": "VhCbRDwlZACg",
        "outputId": "bd1ec810-0b91-47cf-9110-c308d84a1a23",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>upper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A little less than a decade ago, hockey fans w...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The writers of the HBO series The Sopranos too...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Despite claims from the TV news outlet to offe...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After receiving 'subpar' service and experienc...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  upper\n",
              "0  A little less than a decade ago, hockey fans w...      4\n",
              "1  The writers of the HBO series The Sopranos too...      2\n",
              "2  Despite claims from the TV news outlet to offe...      9\n",
              "3  After receiving 'subpar' service and experienc...     13\n",
              "4  After watching his beloved Seattle Mariners pr...      3"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#The number of upper vocab\n",
        "train['upper']=train['Text'].apply(lambda sen:len([x for x in sen.split() if x.isupper()]))\n",
        "train[['Text','upper']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T02:45:45.183804Z",
          "iopub.status.busy": "2022-03-25T02:45:45.183494Z",
          "iopub.status.idle": "2022-03-25T02:45:45.198990Z",
          "shell.execute_reply": "2022-03-25T02:45:45.198088Z",
          "shell.execute_reply.started": "2022-03-25T02:45:45.183770Z"
        },
        "id": "Vb5LV3bwZGxc",
        "outputId": "0c05cc78-539c-485a-976f-b3f3d0bb100f",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Verdict</th>\n",
              "      <th>Text</th>\n",
              "      <th>word_count</th>\n",
              "      <th>char_count</th>\n",
              "      <th>avg_word</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>numerics</th>\n",
              "      <th>upper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A little less than a decade ago, hockey fans w...</td>\n",
              "      <td>147</td>\n",
              "      <td>873</td>\n",
              "      <td>4.979452</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The writers of the HBO series The Sopranos too...</td>\n",
              "      <td>123</td>\n",
              "      <td>715</td>\n",
              "      <td>4.860656</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Despite claims from the TV news outlet to offe...</td>\n",
              "      <td>706</td>\n",
              "      <td>4443</td>\n",
              "      <td>5.302128</td>\n",
              "      <td>219</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>After receiving 'subpar' service and experienc...</td>\n",
              "      <td>706</td>\n",
              "      <td>3913</td>\n",
              "      <td>4.550355</td>\n",
              "      <td>299</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
              "      <td>174</td>\n",
              "      <td>1058</td>\n",
              "      <td>5.115607</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Verdict                                               Text  word_count  \\\n",
              "0        1  A little less than a decade ago, hockey fans w...         147   \n",
              "1        1  The writers of the HBO series The Sopranos too...         123   \n",
              "2        1  Despite claims from the TV news outlet to offe...         706   \n",
              "3        1  After receiving 'subpar' service and experienc...         706   \n",
              "4        1  After watching his beloved Seattle Mariners pr...         174   \n",
              "\n",
              "   char_count  avg_word  stopwords  hashtags  numerics  upper  \n",
              "0         873  4.979452         46         0         0      4  \n",
              "1         715  4.860656         43         0         1      2  \n",
              "2        4443  5.302128        219         0        20      9  \n",
              "3        3913  4.550355        299         0         5     13  \n",
              "4        1058  5.115607         59         0         0      3  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWKH7mKqsBCA"
      },
      "source": [
        "# 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T03:02:09.484265Z",
          "iopub.status.busy": "2022-03-25T03:02:09.483257Z",
          "iopub.status.idle": "2022-03-25T03:06:42.528577Z",
          "shell.execute_reply": "2022-03-25T03:06:42.527517Z",
          "shell.execute_reply.started": "2022-03-25T03:02:09.484175Z"
        },
        "id": "S-FLAucqr5iV",
        "outputId": "df3c8f48-84aa-413d-f2af-89491744c100",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting inflect\n",
            "  Downloading inflect-5.4.0-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: inflect\n",
            "Successfully installed inflect-5.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Delete HTML\n",
        "from bs4 import BeautifulSoup\n",
        "train['Text'] = train['Text'].apply(lambda x: BeautifulSoup(x,'html.parser').get_text())\n",
        "test['Text'] = test['Text'].apply(lambda x: BeautifulSoup(x,'html.parser').get_text())\n",
        "test['Text'].head()\n",
        "\n",
        "#Remove emoji\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "train['Text']=train['Text'].apply(lambda x: remove_emoji(x))\n",
        "test['Text']=test['Text'].apply(lambda x: remove_emoji(x))\n",
        "\n",
        "#Transform to lower letter\n",
        "train['Text'] = train['Text'].apply(lambda x: x.lower())\n",
        "test['Text'] = test['Text'].apply(lambda x: x.lower())\n",
        "test['Text'].head()\n",
        "\n",
        "#Remove punctuation\n",
        "import re\n",
        "train['Text'] = train['Text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
        "test['Text'] = test['Text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
        "test['Text'].head()\n",
        "\n",
        "!pip install inflect\n",
        "\n",
        "#Substitute number\n",
        "import inflect\n",
        "def to_digit(digit):\n",
        "    i = inflect.engine()\n",
        "    if digit.isdigit():\n",
        "        output = i.number_to_words(digit)\n",
        "    else:\n",
        "        output = digit\n",
        "    return output\n",
        "train['Text'] = train['Text'].apply(lambda x: to_digit(x))\n",
        "test['Text'] = test['Text'].apply(lambda x: to_digit(x))\n",
        "test['Text'].head()\n",
        "\n",
        "#Remove the stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop=stopwords.words('english')\n",
        "train['Text']=train['Text'].apply(lambda sen:\" \".join(x for x in sen.split() if x not in stop))\n",
        "test['Text']=test['Text'].apply(lambda sen:\" \".join(x for x in sen.split() if x not in stop))\n",
        "test['Text'].head()\n",
        "\n",
        "#Remove the frequency words\n",
        "freq=pd.Series(' '.join(train['Text']).split()).value_counts()[:10]\n",
        "freq=list(freq.index)\n",
        "train['Text']=train['Text'].apply(lambda sen:' '.join(x for x in sen.split() if x not in freq))\n",
        "test['Text']=test['Text'].apply(lambda sen:' '.join(x for x in sen.split() if x not in freq))\n",
        "test['Text'].head()\n",
        "\n",
        "# Remove the scarce word\n",
        "freq = pd.Series(' '.join(train['Text']).split()).value_counts()[-10:]\n",
        "freq = list(freq.index)\n",
        "train['Text'] = train['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
        "test['Text'] = test['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
        "test['Text'].head()\n",
        "\n",
        "#Noise Removal\n",
        "def text_cleaner(text):\n",
        "    rules = [\n",
        "        {r'>\\s+': u'>'},  # remove spaces after a tag opens or closes\n",
        "        {r'\\s+': u' '},  # replace consecutive spaces\n",
        "        {r'\\s*<br\\s*/?>\\s*': u'\\n'},  # newline after a <br>\n",
        "        {r'</(div)\\s*>\\s*': u'\\n'},  # newline after </p> and </div> and <h1/>...\n",
        "        {r'</(p|h\\d)\\s*>\\s*': u'\\n\\n'},  # newline after </p> and </div> and <h1/>...\n",
        "        {r'<head>.*<\\s*(/head|body)[^>]*>': u''},  # remove <head> to </head>\n",
        "        {r'<a\\s+href=\"([^\"]+)\"[^>]*>.*</a>': r'\\1'},  # show links instead of texts\n",
        "        {r'[ \\t]*<[^<]*?/?>': u''},  # remove remaining tags\n",
        "        {r'^\\s+': u''}  # remove spaces at the beginning\n",
        "    ]\n",
        "    for rule in rules:\n",
        "        for (k, v) in rule.items():\n",
        "            regex = re.compile(k)\n",
        "            text = regex.sub(v, text)\n",
        "        text = text.rstrip()\n",
        "    return text.lower()\n",
        "\n",
        "train['Text']=train['Text'].apply(lambda x: text_cleaner(x))\n",
        "\n",
        "#Lemmatization\n",
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "train['Text']=train['Text'].apply( lambda x:\" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "test['Text']=test['Text'].apply(lambda x:\" \".join([Word(word).lemmatize() for word in x.split()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4aa4uWDr5iX"
      },
      "source": [
        "#4. Feature Engineering "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-PriQ78sF6s"
      },
      "source": [
        "## 4.1 TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T03:08:45.422664Z",
          "iopub.status.busy": "2022-03-25T03:08:45.422323Z",
          "iopub.status.idle": "2022-03-25T03:11:35.356550Z",
          "shell.execute_reply": "2022-03-25T03:11:35.355342Z",
          "shell.execute_reply.started": "2022-03-25T03:08:45.422608Z"
        },
        "id": "_Np8PilFr5iX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Always start with these features. They work (almost) everytime!\n",
        "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
        "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
        "            stop_words = 'english')\n",
        "\n",
        "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
        "tfv.fit(list(train['Text']))\n",
        "xtrain_tfv =  tfv.transform(train['Text']) \n",
        "# xvalid_tfv = tfv.transform(xvalid)\n",
        "xtest_tfv = tfv.transform(test['Text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDRTa5q7r5iX"
      },
      "source": [
        "## 4.2 Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3FOgKAhr5iY"
      },
      "outputs": [],
      "source": [
        "nlp=spacy.load('en_core_web_md',disable=['parser','ner','tagger'])\n",
        "\n",
        "def to_vec(x):\n",
        "    vecs=[]\n",
        "    for s in x:\n",
        "        vecs.append(nlp(s).vector)\n",
        "    return vecs\n",
        "\n",
        "def preprocess(Texts,n_cores=4):\n",
        "    '''\n",
        "    covert texts to vectors by word2vec\n",
        "    '''\n",
        "    texts_split = np.array_split(Texts, n_cores)\n",
        "    pool = Pool(n_cores)\n",
        "    vecs = pool.map(to_vec, texts_split)\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    #vecs=np.array(vecs)#.reshape((-1,300))\n",
        "    vecs1=[]\n",
        "    for ele in vecs:\n",
        "        vecs1.extend(ele)\n",
        "    return np.array(vecs)\n",
        "\n",
        "\n",
        "word2vec_train=preprocess(train['Text'])\n",
        "word2vec_test=preprocess(test['Text'])\n",
        "\n",
        "def trans(data): \n",
        "    vecs1=[]\n",
        "    for ele in data:\n",
        "        vecs1.extend(ele)\n",
        "    return np.array(vecs1).reshape(-1,300)\n",
        "word2vec_train=trans(word2vec_train)\n",
        "word2vec_test=trans(word2vec_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Bc5CCWr5iZ"
      },
      "source": [
        "# 5. Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xof0s7hWr5ia"
      },
      "source": [
        "TF_DFT + RF F1=0.62 when n_tree=100 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-25T03:33:24.697037Z",
          "iopub.status.busy": "2022-03-25T03:33:24.696706Z"
        },
        "id": "fM2gJXzer5ia",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier(1000,n_jobs=-1)\n",
        "clf.fit(xtrain_tfv, train['Verdict'])\n",
        "predictions = clf.predict(xtest_tfv)\n",
        "precision_recall_fscore_support(test['Verdict'], predictions, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg4yi_8ur5ia"
      },
      "outputs": [],
      "source": [
        "clf=RandomForestClassifier(1000,n_jobs=-1)\n",
        "clf.fit(word2vec_train, train['Verdict'])\n",
        "predictions = clf.predict(word2vec_test)\n",
        "precision_recall_fscore_support(test['Verdict'], predictions, average='macro')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "validate-2d-representation-random-forest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
